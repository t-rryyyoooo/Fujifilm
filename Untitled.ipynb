{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "omega = lof10(m) m[mg]/1L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Water Solubility</th>\n",
       "      <th>MaxEStateIndex</th>\n",
       "      <th>MinEStateIndex</th>\n",
       "      <th>MaxAbsEStateIndex</th>\n",
       "      <th>MinAbsEStateIndex</th>\n",
       "      <th>qed</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>HeavyAtomMolWt</th>\n",
       "      <th>ExactMolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1(ccccc1)[C@@H](C)Cl</td>\n",
       "      <td>2.178977</td>\n",
       "      <td>5.803148</td>\n",
       "      <td>0.130741</td>\n",
       "      <td>5.803148</td>\n",
       "      <td>0.130741</td>\n",
       "      <td>0.526469</td>\n",
       "      <td>140.613</td>\n",
       "      <td>131.541</td>\n",
       "      <td>140.039278</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1cc(c(cc1N=C=O)Cl)Cl</td>\n",
       "      <td>1.385606</td>\n",
       "      <td>9.802754</td>\n",
       "      <td>0.377932</td>\n",
       "      <td>9.802754</td>\n",
       "      <td>0.377932</td>\n",
       "      <td>0.491538</td>\n",
       "      <td>188.013</td>\n",
       "      <td>184.989</td>\n",
       "      <td>186.959169</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(c1cc([N+]([O-])=O)c(O)cc1)(F)(F)F</td>\n",
       "      <td>2.606381</td>\n",
       "      <td>12.058762</td>\n",
       "      <td>-4.654306</td>\n",
       "      <td>12.058762</td>\n",
       "      <td>0.287037</td>\n",
       "      <td>0.567231</td>\n",
       "      <td>207.107</td>\n",
       "      <td>203.075</td>\n",
       "      <td>207.014328</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1cc(Cl)ccc1NC(=O)OC</td>\n",
       "      <td>2.535294</td>\n",
       "      <td>10.699816</td>\n",
       "      <td>-0.488590</td>\n",
       "      <td>10.699816</td>\n",
       "      <td>0.488590</td>\n",
       "      <td>0.730313</td>\n",
       "      <td>185.610</td>\n",
       "      <td>177.546</td>\n",
       "      <td>185.024356</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1(c(c(c(Cl)c(c1Cl)Cl)Cl)OC)OC</td>\n",
       "      <td>0.201397</td>\n",
       "      <td>5.874491</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>5.874491</td>\n",
       "      <td>0.149059</td>\n",
       "      <td>0.591254</td>\n",
       "      <td>275.946</td>\n",
       "      <td>269.898</td>\n",
       "      <td>273.912190</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                SMILES  Water Solubility  MaxEStateIndex  \\\n",
       "0                c1(ccccc1)[C@@H](C)Cl          2.178977        5.803148   \n",
       "1                c1cc(c(cc1N=C=O)Cl)Cl          1.385606        9.802754   \n",
       "2  C(c1cc([N+]([O-])=O)c(O)cc1)(F)(F)F          2.606381       12.058762   \n",
       "3                 c1cc(Cl)ccc1NC(=O)OC          2.535294       10.699816   \n",
       "4       c1(c(c(c(Cl)c(c1Cl)Cl)Cl)OC)OC          0.201397        5.874491   \n",
       "\n",
       "   MinEStateIndex  MaxAbsEStateIndex  MinAbsEStateIndex       qed    MolWt  \\\n",
       "0        0.130741           5.803148           0.130741  0.526469  140.613   \n",
       "1        0.377932           9.802754           0.377932  0.491538  188.013   \n",
       "2       -4.654306          12.058762           0.287037  0.567231  207.107   \n",
       "3       -0.488590          10.699816           0.488590  0.730313  185.610   \n",
       "4        0.149059           5.874491           0.149059  0.591254  275.946   \n",
       "\n",
       "   HeavyAtomMolWt  ExactMolWt  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  \\\n",
       "0         131.541  140.039278  ...           0             0           0   \n",
       "1         184.989  186.959169  ...           0             0           0   \n",
       "2         203.075  207.014328  ...           0             0           0   \n",
       "3         177.546  185.024356  ...           0             0           0   \n",
       "4         269.898  273.912190  ...           0             0           0   \n",
       "\n",
       "   fr_term_acetylene  fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  \\\n",
       "0                  0             0            0            0             0   \n",
       "1                  0             0            0            0             0   \n",
       "2                  0             0            0            0             0   \n",
       "3                  0             0            0            0             0   \n",
       "4                  0             0            0            0             0   \n",
       "\n",
       "   fr_unbrch_alkane  fr_urea  \n",
       "0                 0        0  \n",
       "1                 0        0  \n",
       "2                 0        0  \n",
       "3                 0        0  \n",
       "4                 0        0  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "for column in df.columns:\n",
    "    if column in [\"SMILES\", \"Water Solubility\"]:\n",
    "        continue\n",
    "    columns.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape :  (1053, 200)\n"
     ]
    }
   ],
   "source": [
    "X = df.loc[:, columns].values\n",
    "Y = df.loc[:, \"Water Solubility\"].values\n",
    "\n",
    "print(\"X shape : \", X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K =  7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[499]\tvalid_0's l2: 0.222633\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[339]\tvalid_0's l2: 0.278747\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's l2: 0.285373\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[512]\tvalid_0's l2: 0.892994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's l2: 0.328809\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's l2: 0.382046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[553]\tvalid_0's l2: 0.332307\n"
     ]
    }
   ],
   "source": [
    "r2_scores = []\n",
    "K = 7\n",
    "\n",
    "print(\"K = \", K)\n",
    "kf = KFold(n_splits = K, shuffle=True, random_state=42).split(X_train, Y_train)\n",
    "gbm = [None] * K\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf):\n",
    "    x_train = X_train[train_idx]\n",
    "    y_train = Y_train[train_idx]\n",
    "    x_test = X_train[test_idx]\n",
    "    y_test = Y_train[test_idx]\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_test = lgb.Dataset(x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "    # LightGBM parameters\n",
    "    params = {\n",
    "            'task' : 'train',\n",
    "            'boosting_type' : 'gbdt',\n",
    "            'objective' : 'regression',\n",
    "            'metric' : \"mse\",\n",
    "            'num_leaves' : 32,\n",
    "            'learning_rate' : 0.01,\n",
    "            #'feature_fraction' : 0.9,\n",
    "            #'bagging_fraction' : 0.8,\n",
    "            #'bagging_freq': 5,\n",
    "            'random_state' : 42\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm[i] = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=lgb_test,\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=10000\n",
    "    )\n",
    "\n",
    "\n",
    "y_preds = np.array([0.] * len(Y_test))\n",
    "for x in range(K):\n",
    "    pred = gbm[x].predict(X_test, num_iteration=gbm[x].best_iteration)\n",
    "    y_preds += pred\n",
    "\n",
    "\n",
    "y_preds = (y_preds / K)\n",
    "\n",
    "r2 = r2_score(y_preds, Y_test)\n",
    "r2_scores.append(r2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart the chemical structure from SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chartChemicalStructure(df):\n",
    "    paths = []\n",
    "    dir_name = Path(\"image\")\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "    \n",
    "    for i, smiles in enumerate(df[\"SMILES\"]):\n",
    "        path = dir_name / (str(i).zfill(4) + \".png\")\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        Draw.MolToFile(mol, path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-88c58255e965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mefficientnet_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import cloudpickle\n",
    "from pathlib import Path\n",
    "import  pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from pytorch_lightning.loggers import CometLogger\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetTransform():\n",
    "    def __init__(self, input_size):\n",
    "        self.transforms = {\n",
    "            \"train\" : transforms.Compose([\n",
    "                \n",
    "                RandomEqualizeHist(p=-0.1),\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.ToTensor(), \n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "\n",
    "            ]), \n",
    "            \"val\" : transforms.Compose([\n",
    "                RandomEqualizeHist(p=-0.1),\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.Grayscale(num_output_channels=3),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "            ])\n",
    "        }\n",
    "        \n",
    "    def __call__(self, phase, image):\n",
    "        image = self.transforms[phase](image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetDataset(Dataset):\n",
    "    def __init__(self, dataset, series, transform, phase=\"train\"):\n",
    "        super(EfficientNetDataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.series = series\n",
    "        self.phase = phase\n",
    "        self.transform = transform\n",
    "    \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.series)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.dataset[index]\n",
    "        label = self.series[index]\n",
    "        #label = label[None,...]\n",
    "        #image = cv2.imread(path, 0)\n",
    "        image = Image.open(path)\n",
    "        image = self.transform(self.phase, image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1102c5cdebbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEfficientNetSystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_series\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEfficientNetSystem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_class):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "        \n",
    "        #Actually, you should set learning rate for each layer.\n",
    "        for params in self.model.parameters():\n",
    "            params.requires_grad = True\n",
    "        \n",
    "        num_ftrs = self.model._fc.in_features\n",
    "        self.model._fc = nn.Linear(num_ftrs, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class BestAndLatestModelCheckpoint(object):\n",
    "    def __init__(self, save_directory, best_name=\"best.pkl\", latest_name=\"latest.pkl\"):\n",
    "        self.best_value = 10**9\n",
    "        self.save_directory= Path(save_directory)\n",
    "        self.save_directory.mkdir(parents=True, exist_ok=True)\n",
    "        self.best_path = self.save_directory / best_name\n",
    "        self.latest_path = self.save_directory / latest_name\n",
    "\n",
    "\n",
    "    def __call__(self, pred, model):\n",
    "        if pred < self.best_value:\n",
    "            self.best_value = pred\n",
    "\n",
    "            with open(self.best_path, \"wb\") as f:\n",
    "                cloudpickle.dump(model, f)\n",
    "        \n",
    "        with open(self.latest_path, \"wb\") as f:\n",
    "            cloudpickle.dump(model, f)\n",
    "\n",
    "\n",
    "class EfficientNetSystem(pl.LightningModule):\n",
    "    def __init__(self, num_class, train_dataset, train_series, val_dataset, val_series, input_size, batch_size, checkpoint, lr=0.001, num_workers=6):\n",
    "        super(EfficientNetSystem, self).__init__()\n",
    "        use_cuda = torch.cuda.is_available() and True\n",
    "        self.device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self.train_dataset = train_dataset\n",
    "        self.train_series = train_series\n",
    "        self.val_dataset = val_dataset\n",
    "        self.val_series = val_series\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.learning_rate = lr\n",
    "        self.model = EfficientNetModel(num_class).to(self.device)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.checkpoint = checkpoint\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        image, label = batch\n",
    "        image = image.to(self.device, dtype=torch.float)\n",
    "        label = label.to(self.device, dtype=torch.long)\n",
    "        \n",
    "        pred = self.forward(image)\n",
    "\n",
    "        loss = self.loss(pred, label)\n",
    "                \n",
    "        tensorboard_logs = {\n",
    "            \"train_loss\" : loss\n",
    "        }\n",
    "        \n",
    "        return {\"loss\" : loss, \"log\" : tensorboard_logs}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        image, label = batch\n",
    "        image = image.to(self.device, dtype=torch.float)\n",
    "        label = label.to(self.device, dtype=torch.long)\n",
    "        \n",
    "        pred = self.forward(image)\n",
    "\n",
    "        loss = self.loss(pred, label)\n",
    "        \n",
    "        tensorboard_logs = {\n",
    "            \"val_loss\" : loss,\n",
    "           # \"val_f1\" : f1\n",
    "        }\n",
    "        \n",
    "        return {\"val_loss\" : loss, \"log\" : tensorboard_logs}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        #avg_f1 = torch.stack([x[\"log\"][\"val_f1\"] for x in outputs]).mean()\n",
    "        \n",
    "        self.checkpoint(avg_loss.item(), self.model)\n",
    "        \n",
    "        tensorboard_logs = {\n",
    "            \"val_loss\" : avg_loss, \n",
    "           # \"val_f1\" : avg_f1\n",
    "        }\n",
    "        progress_bar = {\n",
    "            \"val_loss\" : avg_loss,\n",
    "           # \"val_f1\" : avg_f1\n",
    "        }\n",
    "        \n",
    "        return {\"avg_val_loss\" : avg_loss, \"log\" : tensorboard_logs, \"progress_bar\" : progress_bar}\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        return optimizer\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = EfficientNetDataset(\n",
    "            dataset = self.train_dataset, \n",
    "            series = self.train_series,\n",
    "            transform = EfficientNetTransform(self.input_size)\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            shuffle = True, \n",
    "            batch_size = self.batch_size,\n",
    "            num_workers = self.num_workers\n",
    "        )\n",
    "        \n",
    "        return train_loader\n",
    "    \n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = EfficientNetDataset(\n",
    "            dataset = self.val_dataset, \n",
    "            phase=\"val\", \n",
    "            series = self.val_series, \n",
    "            transform = EfficientNetTransform(self.input_size)\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size = self.batch_size, \n",
    "            num_workers = self.num_workers\n",
    "        )\n",
    "        \n",
    "        return val_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b335e52bedb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"character\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataset, test_dataset, train_series, test_series = train_test_split(df_train['image_path'].values, df_train['character'].values,stratify=df_train['character'],\n\u001b[1;32m      5\u001b[0m                      test_size=0.2, random_state=42)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = df_train[\"image_path\"]\n",
    "series = df_train[\"character\"]\n",
    "\n",
    "train_dataset, test_dataset, train_series, test_series = train_test_split(df_train['image_path'].values, df_train['character'].values,stratify=df_train['character'],\n",
    "                     test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset, val_dataset, train_series, val_series = train_test_split(train_dataset, train_series,stratify=train_series,\n",
    "                     test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EfficientNetSystem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8b59a7c9b458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m system = EfficientNetSystem(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mnum_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_series\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EfficientNetSystem' is not defined"
     ]
    }
   ],
   "source": [
    "system = EfficientNetSystem(\n",
    "    num_class = num_class,\n",
    "    train_dataset = train_dataset,\n",
    "    train_series = train_series, \n",
    "    val_dataset = val_dataset,\n",
    "    val_series = val_series,\n",
    "    input_size = input_size,\n",
    "    batch_size = 64,\n",
    "    checkpoint = BestAndLatestModelCheckpoint(\"model\")\n",
    ")\n",
    "\n",
    "# comet_logger = CometLogger(\n",
    "#             api_key = \"IowbTppLPOohqhcDtzxw76Cot\",\n",
    "#             project_name = \"mewcket\",  \n",
    "#             experiment_name = \"Efficient Net\",\n",
    "#             save_dir = \"log\"\n",
    "# )\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    num_sanity_val_step = 0,\n",
    "    max_epochs = 10,\n",
    "    checkpoint_callback = None,\n",
    "    #logger = comet_logger, \n",
    "    gpus = -1,\n",
    "    distributed_backend='dp'\n",
    ")\n",
    "trainer.fit(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/best.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4e9c5fe707b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model/best.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgpuid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/best.pkl'"
     ]
    }
   ],
   "source": [
    "model_path = \"model/best.pkl\"\n",
    "gpuid = [0, 1]\n",
    "with open(model_path, \"rb\") as f:\n",
    "    model = cloudpickle.load(f)\n",
    "    model = torch.nn.DataParallel(model, device_ids=gpuid)\n",
    "\n",
    "model.eval()\n",
    "pred_list = []\n",
    "transform = EfficientNetTransform((input_size))\n",
    "for path in tqdm(test_dataset):\n",
    "    image = Image.open(path)\n",
    "    image = transform(\"val\", image)\n",
    "    image = image[None, ...]\n",
    "    \n",
    "    pred = model(image)\n",
    "    _, pred = pred.topk(1, 1, True, True)\n",
    "    pred = pred.to(\"cpu\").detach().numpy()\n",
    "    pred = np.squeeze(pred)\n",
    "    pred_list.append(pred)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
